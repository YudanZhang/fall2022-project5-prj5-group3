{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "AffwCk3BVMt8",
        "outputId": "209cc0ea-1762-4bf8-c73e-82772d59a061"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.8/dist-packages (20221105)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.8/dist-packages (from pdfminer.six) (38.0.4)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from pdfminer.six) (2.1.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography>=36.0.0->pdfminer.six) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.21)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.8/dist-packages (2.11.2)\n",
            "Requirement already satisfied: typing_extensions>=3.10.0.0 in /usr/local/lib/python3.8/dist-packages (from PyPDF2) (4.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.8/dist-packages (0.7.6)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.8/dist-packages (from pdfplumber) (9.3.0)\n",
            "Requirement already satisfied: pdfminer.six==20221105 in /usr/local/lib/python3.8/dist-packages (from pdfplumber) (20221105)\n",
            "Requirement already satisfied: Wand>=0.6.10 in /usr/local/lib/python3.8/dist-packages (from pdfplumber) (0.6.10)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from pdfminer.six==20221105->pdfplumber) (2.1.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.8/dist-packages (from pdfminer.six==20221105->pdfplumber) (38.0.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (2.21)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ZEYA AHMAD(929)8440942  | za2291@columbia.edu | https://www.linkedin.com/in/zeyaahmad/ | https://github.com/zeya30EDUCATIONCOLUMBIA UNIVERSITY Sep 2021-Dec 2022(Expected)M.A. in Statistics (Machine Learning track)Relevant Courses:Applied Linear Regression Models, Statistical Machine Learning, Databases, TensorFlow in Python, EDABIRLA INSTITUTE OF TECHNOLOGY AND SCIENCE(BITS),PILANI Sep 2015-June 2019B.E.(Hons.) in Computer ScienceRelevant Courses:Data Mining,Information Retrieval,Artificial Intelligence,Data Structures & Algorithms,OptimizationTECHNICAL SKILLSProgramming Languages: Python , R ,Java, SQL, SAS,C++ , HTML5/CSS, Microsoft ExcelLibraries/Framework:TensorFlow,Keras,PyTorch,Scikit-Learn,Pandas,NumPy,SciPy,Matplotlib,Seaborn,BeautifulSoup,Selenium,NLTK,RASA, Flask,tidyr,dplyr,ggplot2,R shiny,StreamlitSpecialization:Machine Learning(GLM,Linear Regression,LogisticRegression,KNN,Random Forest,Clustering,Decision Trees ,SVM,Classification),Data Analysis(A/B Testing,Data Modeling),Business Intelligence(Tableau,ProductAnalysis),Feature Engineering,Statistical  Modeling, Web Scraping, NLP, Predictive Modeling, Time Series Analysis, Hypothesis Testing, Reinforcement LearningDatabase/ETL: MySQL,MongoDB,Amazon DynamoDBOther Tools:Tableau,Spark,Hadoop,Git,AWS(Glue ETL,Athena,EC2,Lambda,RDS,SageMaker,S3),PowerBI,Google Cloud PlatformPROFESSIONAL EXPERIENCENEXTGEN HQ New York City, USAData Science & Strategy Consultant May 2022 - Aug2022 Built SQL scripts to generate weekly KPI reports, which decreased 30% of the data generating time Evaluated 3 A/B tests using Python & SQL to make informed recommendations on product changes. Used Python to build a decision tree with an accuracy of 86%, resulting in a 3% increase in VIP conversion Designed and conducted experiments on incentive programs, which increased VIP retention by 10%CUREFY New Delhi, IndiaData Science Intern Sep 2020 - April 2021 Developed a Healthcare Chatbot for online self-diagnosis and directing users to the appropriate medical practitioner based onsymptoms/text input by the user,usingInfermedicaAPI,RASA NLU framework and Python spaCy for NLP.JOHNSON CONTROLS Dubai, UAEBusiness Intelligence Intern Aug 2018- Jan 2019 Used SQL to build 6 dashboards from 1M+ customer data, which caused saving 10 work hours per week Generated 8 Tableau reports to support decision-making in: CRM, sales pipeline, recruiting, invoicing and ticketing.PROJECTSIMDB Movie Recommendation System Project |Kaggle| Python Mar 2021- Jun 2021 Created a hybrid recommendation system(Collaborative Filtering + Content-Based Filtering) basedon10k+usersand45kmoviesacross 30 years, that resulted in a 5% increase in basket size and improved RMSE from 1.34 to 0.86. Constructed collaborativefiltering and matrix factorizations using Alternating Least Squares with a Temporal Dynamics Regularization. Constructed content-based model through TF-IDF word embedding, LDA topic modeling, Pearson Correlation, and SentimentAnalysis (Natural Language Processing). Recommended top N similar movies with positive user comments.Analyzing neighborhoods in Bangalore | Capstone Project| Python Jun 2020 - Sep 2020 Implemented K-means Clustering algorithm to analyze and select the most suitable locations in Bangalore for opening a newshopping mall by Web Scraping Wikipedia page containing list oftheneighborhoodsinBangalore.UsedFoursquareAPItoobtainthe venue data for the neighborhoods and Geocoder library to obtain  geographical coordinates of the neighborhoods.Amazon Fake Review Detection | Kaggle | Python Sep 2019 - Dec 2019 Used text-mining and classification model to analyze 4+ million customer reviews of mobile phones sold on Amazon to predictitem ratings and prevent fake reviews with over 85% recall score. Cleaned unstructured text data by handling missing values and categoricaldata,processedsegmentation,andvectorizeddatafromtext into numeric using TF-IDF.Constructed data pipelines to train models including Decision Tree, Naive Bayes, and LogisticRegression to predict rating based on reviews with over 85% accuracy and evaluated models by AUROC and F1 score.Predicting Success of Spotify Songs |  BITS Pilani | Python Mar 2019 - May 2019 Used a dataset of 228,000 Spotify Tracks to predict popularity of a track(greater than 57 popularity) using audio-based metricssuch as key, mode, anddanceabilitywithoutexternalmetricssuchasartistname,genre,andreleasedate.RandomForestClassifierwas the best performing algorithm (92 % accuracy and 86.4% AUC).'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "!pip3 install pdfminer.six \n",
        "!pip install PyPDF2\n",
        "!pip install pdfplumber\n",
        "import pdfminer.high_level\n",
        "from pdfminer.high_level import extract_text\n",
        "\n",
        "import PyPDF2,pdfplumber \n",
        " \n",
        "\n",
        "CV_File=open('/content/ZeyaAhmadResume.pdf','rb')\n",
        "Script=PyPDF2.PdfFileReader(CV_File)\n",
        "pages=Script.numPages\n",
        "\n",
        "Script = []\n",
        "with pdfplumber.open(CV_File) as pdf:\n",
        "    for i in range (0,pages):\n",
        "        page=pdf.pages[i]\n",
        "        text=page.extract_text()\n",
        "        # print (text)\n",
        "        Script.append(text)\n",
        "        \n",
        "Script=''.join(Script)\n",
        "CV_Clear = Script.replace(\"\\n\",\"\").replace('‚óè', \"\")\n",
        "CV_Clear    \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "2v4IZbJfyxr2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# search inputs: \n",
        "title = input('Enter your desired position: ').strip()\n",
        "location = input('Enter your desired location: ').strip()\n",
        "no_pages = int(input('Enter the # of pages to scrape: '))\n",
        "\n",
        "\n",
        "info = []\n",
        "headers = {'User-agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36'}\n",
        "\n",
        "for page in range(no_pages):\n",
        "    getVars = {'keywords' : title, 'location' : location ,'sort' : 'date', 'start': str(no_pages*10)}\n",
        "    url = ('https://www.linkedin.com/jobs/search?' + urllib.parse.urlencode(getVars))\n",
        "    print(url)\n",
        "    r = requests.get(url, headers=headers)\n",
        "    html = r.content\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "    \n",
        "    jobs = soup.find_all('div', class_ = 'base-card relative w-full hover:no-underline focus:no-underline base-card--link base-search-card base-search-card--link job-search-card')\n",
        "    \n",
        "    for job in jobs:\n",
        "        title = str(job.find('h3', class_='base-search-card__title').text.strip())\n",
        "        company = str(job.find('h4', class_='base-search-card__subtitle').text.strip())\n",
        "        post_date = datetime.strptime(job.find('time')['datetime'], '%Y-%m-%d').date()\n",
        "        link = job.find('a', class_='base-card__full-link')['href']\n",
        "        \n",
        "        info.append([title,company,post_date,link])\n",
        "    \n",
        "\n",
        "info_dict_list = defaultdict(list)\n",
        "\n",
        "cols = ['Job_title','Company','Job_posted_date','Link']\n",
        "info_table = pd.DataFrame(info, columns = cols)\n",
        "# sort by post date\n",
        "info_table = info_table.sort_values(by = 'Job_posted_date', ascending = False).reset_index(drop=True)\n",
        "info_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 892
        },
        "id": "p5yRTTWE_Lo0",
        "outputId": "4ac60a65-20e0-4074-fa52-05292fb87743"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your desired position: Data Scientist\n",
            "Enter your desired location: New York\n",
            "Enter the # of pages to scrape: 1\n",
            "https://www.linkedin.com/jobs/search?keywords=Data+Scientist&location=New+York&sort=date&start=10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    Job_title                         Company  \\\n",
              "0                     Data Scientist (Remote)                       Broadlume   \n",
              "1                  Data Scientist, Accounting                         Spotify   \n",
              "2     Data Scientist (Deep Learning), Peacock                         Peacock   \n",
              "3                              Data Scientist                          Amicus   \n",
              "4                    Data Scientist Full Time               Bardess Group Ltd   \n",
              "5                              Data Scientist                          TikTok   \n",
              "6                              Data Scientist              The New York Times   \n",
              "7                              Data Scientist                       Grammarly   \n",
              "8                        Data Scientist [NYC]                     CarbonChain   \n",
              "9                            Data Scientist I         The Walt Disney Company   \n",
              "10           Data Scientist I, Risk Analytics                    Oscar Health   \n",
              "11   Data Scientist - Global Decision Science                American Express   \n",
              "12  Machine Learning Engineer - New Grad 2023                        Nextdoor   \n",
              "13                             Data Scientist                          TikTok   \n",
              "14                             Data Scientist                         Epsilon   \n",
              "15                             Data Scientist  Carrie Rikon & Associates, LLC   \n",
              "16                  Machine Learning Engineer                         Verneek   \n",
              "17                    Data Scientist, Product                           Asana   \n",
              "18                             Data Scientist                    Revelio Labs   \n",
              "19                             Data Scientist                      Afficiency   \n",
              "20                             Data Scientist                      Afficiency   \n",
              "21                             Data Scientist                      IntelliPro   \n",
              "22                             Data Scientist  Carrie Rikon & Associates, LLC   \n",
              "23                             Data Scientist                         Experfy   \n",
              "24                             Data Scientist   Atlantic Partners Corporation   \n",
              "\n",
              "   Job_posted_date                                               Link  \n",
              "0       2022-12-07  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "1       2022-12-06  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "2       2022-12-06  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "3       2022-12-06  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "4       2022-12-06  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "5       2022-12-03  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "6       2022-12-03  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "7       2022-12-02  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "8       2022-12-02  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "9       2022-12-01  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "10      2022-12-01  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "11      2022-12-01  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "12      2022-11-30  https://www.linkedin.com/jobs/view/machine-lea...  \n",
              "13      2022-11-21  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "14      2022-11-18  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "15      2022-11-18  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "16      2022-11-17  https://www.linkedin.com/jobs/view/machine-lea...  \n",
              "17      2022-11-16  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "18      2022-11-11  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "19      2022-11-09  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "20      2022-11-03  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "21      2022-11-01  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "22      2022-10-31  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "23      2022-10-27  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "24      2022-10-23  https://www.linkedin.com/jobs/view/data-scient...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fed1c70d-8770-4cc1-8b62-255e2e515a28\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Job_title</th>\n",
              "      <th>Company</th>\n",
              "      <th>Job_posted_date</th>\n",
              "      <th>Link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data Scientist (Remote)</td>\n",
              "      <td>Broadlume</td>\n",
              "      <td>2022-12-07</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Data Scientist, Accounting</td>\n",
              "      <td>Spotify</td>\n",
              "      <td>2022-12-06</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Data Scientist (Deep Learning), Peacock</td>\n",
              "      <td>Peacock</td>\n",
              "      <td>2022-12-06</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Amicus</td>\n",
              "      <td>2022-12-06</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Data Scientist Full Time</td>\n",
              "      <td>Bardess Group Ltd</td>\n",
              "      <td>2022-12-06</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>TikTok</td>\n",
              "      <td>2022-12-03</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>2022-12-03</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Grammarly</td>\n",
              "      <td>2022-12-02</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Data Scientist [NYC]</td>\n",
              "      <td>CarbonChain</td>\n",
              "      <td>2022-12-02</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Data Scientist I</td>\n",
              "      <td>The Walt Disney Company</td>\n",
              "      <td>2022-12-01</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Data Scientist I, Risk Analytics</td>\n",
              "      <td>Oscar Health</td>\n",
              "      <td>2022-12-01</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Data Scientist - Global Decision Science</td>\n",
              "      <td>American Express</td>\n",
              "      <td>2022-12-01</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Machine Learning Engineer - New Grad 2023</td>\n",
              "      <td>Nextdoor</td>\n",
              "      <td>2022-11-30</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>TikTok</td>\n",
              "      <td>2022-11-21</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Epsilon</td>\n",
              "      <td>2022-11-18</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Carrie Rikon &amp; Associates, LLC</td>\n",
              "      <td>2022-11-18</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Machine Learning Engineer</td>\n",
              "      <td>Verneek</td>\n",
              "      <td>2022-11-17</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Data Scientist, Product</td>\n",
              "      <td>Asana</td>\n",
              "      <td>2022-11-16</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Revelio Labs</td>\n",
              "      <td>2022-11-11</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Afficiency</td>\n",
              "      <td>2022-11-09</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Afficiency</td>\n",
              "      <td>2022-11-03</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>IntelliPro</td>\n",
              "      <td>2022-11-01</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Carrie Rikon &amp; Associates, LLC</td>\n",
              "      <td>2022-10-31</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Experfy</td>\n",
              "      <td>2022-10-27</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Atlantic Partners Corporation</td>\n",
              "      <td>2022-10-23</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fed1c70d-8770-4cc1-8b62-255e2e515a28')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fed1c70d-8770-4cc1-8b62-255e2e515a28 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fed1c70d-8770-4cc1-8b62-255e2e515a28');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "iS4ZLt0f8hc5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# search inputs: \n",
        "title = input('Enter your desired position: ').strip()\n",
        "location = input('Enter your desired location: ').strip()\n",
        "no_pages = int(input('Enter the # of pages to scrape: '))\n",
        "\n",
        "\n",
        "info = []\n",
        "headers = {'User-agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36'}\n",
        "\n",
        "for page in range(no_pages):\n",
        "    getVars = {'keywords' : title, 'location' : location ,'sort' : 'date', 'start': str(no_pages*10)}\n",
        "    url = ('https://www.linkedin.com/jobs/search?' + urllib.parse.urlencode(getVars))\n",
        "    print(url)\n",
        "    r = requests.get(url, headers=headers)\n",
        "    html = r.content\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "    \n",
        "    jobs = soup.find_all('div', class_ = 'base-card relative w-full hover:no-underline focus:no-underline base-card--link base-search-card base-search-card--link job-search-card')\n",
        "    \n",
        "    for job in jobs:\n",
        "        title = str(job.find('h3', class_='base-search-card__title').text.strip())\n",
        "        company = str(job.find('h4', class_='base-search-card__subtitle').text.strip())\n",
        "        post_date = datetime.strptime(job.find('time')['datetime'], '%Y-%m-%d').date()\n",
        "        link = job.find('a', class_='base-card__full-link')['href']\n",
        "        \n",
        "        info.append([title,company,post_date,link])\n",
        "    \n",
        "\n",
        "info_dict_list = defaultdict(list)\n",
        "\n",
        "cols = ['Job_title','Company','Job_posted_date','Link']\n",
        "info_table = pd.DataFrame(info, columns = cols)\n",
        "# sort by post date\n",
        "info_table = info_table.sort_values(by = 'Job_posted_date', ascending = False).reset_index(drop=True)\n",
        "info_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 892
        },
        "id": "ZbNqLBWlM50b",
        "outputId": "05701e4a-9c94-4b5d-8d83-a0499fc876da"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your desired position: Data Scientist\n",
            "Enter your desired location: New York\n",
            "Enter the # of pages to scrape: 1\n",
            "https://www.linkedin.com/jobs/search?keywords=Data+Scientist&location=New+York&sort=date&start=10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    Job_title                         Company  \\\n",
              "0                     Data Scientist (Remote)                       Broadlume   \n",
              "1                  Data Scientist, Accounting                         Spotify   \n",
              "2     Data Scientist (Deep Learning), Peacock                         Peacock   \n",
              "3                              Data Scientist                          Amicus   \n",
              "4                    Data Scientist Full Time               Bardess Group Ltd   \n",
              "5                              Data Scientist                          TikTok   \n",
              "6                              Data Scientist              The New York Times   \n",
              "7                              Data Scientist                       Grammarly   \n",
              "8                        Data Scientist [NYC]                     CarbonChain   \n",
              "9                            Data Scientist I         The Walt Disney Company   \n",
              "10           Data Scientist I, Risk Analytics                    Oscar Health   \n",
              "11   Data Scientist - Global Decision Science                American Express   \n",
              "12  Machine Learning Engineer - New Grad 2023                        Nextdoor   \n",
              "13                             Data Scientist                          TikTok   \n",
              "14                             Data Scientist                         Epsilon   \n",
              "15                             Data Scientist  Carrie Rikon & Associates, LLC   \n",
              "16                  Machine Learning Engineer                         Verneek   \n",
              "17                    Data Scientist, Product                           Asana   \n",
              "18                             Data Scientist                    Revelio Labs   \n",
              "19                             Data Scientist                      Afficiency   \n",
              "20                             Data Scientist                      Afficiency   \n",
              "21                             Data Scientist                      IntelliPro   \n",
              "22                             Data Scientist  Carrie Rikon & Associates, LLC   \n",
              "23                             Data Scientist                         Experfy   \n",
              "24                             Data Scientist   Atlantic Partners Corporation   \n",
              "\n",
              "   Job_posted_date                                               Link  \n",
              "0       2022-12-07  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "1       2022-12-06  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "2       2022-12-06  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "3       2022-12-06  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "4       2022-12-06  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "5       2022-12-03  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "6       2022-12-03  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "7       2022-12-02  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "8       2022-12-02  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "9       2022-12-01  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "10      2022-12-01  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "11      2022-12-01  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "12      2022-11-30  https://www.linkedin.com/jobs/view/machine-lea...  \n",
              "13      2022-11-21  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "14      2022-11-18  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "15      2022-11-18  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "16      2022-11-17  https://www.linkedin.com/jobs/view/machine-lea...  \n",
              "17      2022-11-16  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "18      2022-11-11  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "19      2022-11-09  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "20      2022-11-03  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "21      2022-11-01  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "22      2022-10-31  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "23      2022-10-27  https://www.linkedin.com/jobs/view/data-scient...  \n",
              "24      2022-10-23  https://www.linkedin.com/jobs/view/data-scient...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f4771cb-efd8-4097-8da6-c57ba8c5784c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Job_title</th>\n",
              "      <th>Company</th>\n",
              "      <th>Job_posted_date</th>\n",
              "      <th>Link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data Scientist (Remote)</td>\n",
              "      <td>Broadlume</td>\n",
              "      <td>2022-12-07</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Data Scientist, Accounting</td>\n",
              "      <td>Spotify</td>\n",
              "      <td>2022-12-06</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Data Scientist (Deep Learning), Peacock</td>\n",
              "      <td>Peacock</td>\n",
              "      <td>2022-12-06</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Amicus</td>\n",
              "      <td>2022-12-06</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Data Scientist Full Time</td>\n",
              "      <td>Bardess Group Ltd</td>\n",
              "      <td>2022-12-06</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>TikTok</td>\n",
              "      <td>2022-12-03</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>2022-12-03</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Grammarly</td>\n",
              "      <td>2022-12-02</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Data Scientist [NYC]</td>\n",
              "      <td>CarbonChain</td>\n",
              "      <td>2022-12-02</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Data Scientist I</td>\n",
              "      <td>The Walt Disney Company</td>\n",
              "      <td>2022-12-01</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Data Scientist I, Risk Analytics</td>\n",
              "      <td>Oscar Health</td>\n",
              "      <td>2022-12-01</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Data Scientist - Global Decision Science</td>\n",
              "      <td>American Express</td>\n",
              "      <td>2022-12-01</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Machine Learning Engineer - New Grad 2023</td>\n",
              "      <td>Nextdoor</td>\n",
              "      <td>2022-11-30</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>TikTok</td>\n",
              "      <td>2022-11-21</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Epsilon</td>\n",
              "      <td>2022-11-18</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Carrie Rikon &amp; Associates, LLC</td>\n",
              "      <td>2022-11-18</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Machine Learning Engineer</td>\n",
              "      <td>Verneek</td>\n",
              "      <td>2022-11-17</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Data Scientist, Product</td>\n",
              "      <td>Asana</td>\n",
              "      <td>2022-11-16</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Revelio Labs</td>\n",
              "      <td>2022-11-11</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Afficiency</td>\n",
              "      <td>2022-11-09</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Afficiency</td>\n",
              "      <td>2022-11-03</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>IntelliPro</td>\n",
              "      <td>2022-11-01</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Carrie Rikon &amp; Associates, LLC</td>\n",
              "      <td>2022-10-31</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Experfy</td>\n",
              "      <td>2022-10-27</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Atlantic Partners Corporation</td>\n",
              "      <td>2022-10-23</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f4771cb-efd8-4097-8da6-c57ba8c5784c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1f4771cb-efd8-4097-8da6-c57ba8c5784c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1f4771cb-efd8-4097-8da6-c57ba8c5784c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "match_percent = []\n",
        "for l in info_table['Link']: \n",
        "    \n",
        "    # extract job description from 2nd webpage (ie, main page for each job post)\n",
        "    r = requests.get(l, headers=headers)\n",
        "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
        "    job_description = soup.find('div', class_='show-more-less-html__markup show-more-less-html__markup--clamp-after-5').text.replace(\"\\n\",\"\")\n",
        "    \n",
        "    # calculate match percentage \n",
        "    Match_Test = [CV_Clear,job_description]\n",
        "    cv = CountVectorizer()\n",
        "    count_matrix = cv.fit_transform(Match_Test)\n",
        "    MatchPercentage = cosine_similarity(count_matrix)[0][1]*100\n",
        "    match_percent.append(MatchPercentage)\n",
        "    \n",
        "match_percent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_frh_jPdfmzp",
        "outputId": "ca83b083-81cf-4d04-f8d0-c15db7f47db0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[55.16608019424053,\n",
              " 58.897014533846736,\n",
              " 62.87477273146077,\n",
              " 47.97039108016488,\n",
              " 57.16923972619171,\n",
              " 60.38836638346838,\n",
              " 59.26137968901206,\n",
              " 55.87402534246038,\n",
              " 58.21452573589434,\n",
              " 65.69621938785806,\n",
              " 54.39556755530957,\n",
              " 62.232565393424366,\n",
              " 56.472088198019954,\n",
              " 60.544714583693995,\n",
              " 61.385708785596115,\n",
              " 58.595425700676294,\n",
              " 47.07516851205012,\n",
              " 58.1760449642378,\n",
              " 51.27348825819878,\n",
              " 62.93423142075299,\n",
              " 63.03357713376832,\n",
              " 61.26832670057334,\n",
              " 58.211078246346226,\n",
              " 42.44909161678472,\n",
              " 58.68186189223499]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "match_percent = pd.DataFrame(match_percent, columns = ['Matching_percentage'])\n",
        "final_info_table = pd.concat([info_table, match_percent], axis=1)\n",
        "final_info_table = final_info_table.sort_values(by = 'Matching_percentage', axis = 0, ascending=False)"
      ],
      "metadata": {
        "id": "4Y_EQvJkgZlg"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# export tp csv file: \n",
        "final_info_table.to_csv('final_info_table1.csv', index=False)\n",
        "final_info_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "id": "roBEOmcRgnAL",
        "outputId": "b11d16dc-d225-4ab7-f4fd-4632f8121284"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    Job_title                         Company  \\\n",
              "9                            Data Scientist I         The Walt Disney Company   \n",
              "20                             Data Scientist                      Afficiency   \n",
              "19                             Data Scientist                      Afficiency   \n",
              "2     Data Scientist (Deep Learning), Peacock                         Peacock   \n",
              "11   Data Scientist - Global Decision Science                American Express   \n",
              "14                             Data Scientist                         Epsilon   \n",
              "21                             Data Scientist                      IntelliPro   \n",
              "13                             Data Scientist                          TikTok   \n",
              "5                              Data Scientist                          TikTok   \n",
              "6                              Data Scientist              The New York Times   \n",
              "1                  Data Scientist, Accounting                         Spotify   \n",
              "24                             Data Scientist   Atlantic Partners Corporation   \n",
              "15                             Data Scientist  Carrie Rikon & Associates, LLC   \n",
              "8                        Data Scientist [NYC]                     CarbonChain   \n",
              "22                             Data Scientist  Carrie Rikon & Associates, LLC   \n",
              "17                    Data Scientist, Product                           Asana   \n",
              "4                    Data Scientist Full Time               Bardess Group Ltd   \n",
              "12  Machine Learning Engineer - New Grad 2023                        Nextdoor   \n",
              "7                              Data Scientist                       Grammarly   \n",
              "0                     Data Scientist (Remote)                       Broadlume   \n",
              "10           Data Scientist I, Risk Analytics                    Oscar Health   \n",
              "18                             Data Scientist                    Revelio Labs   \n",
              "3                              Data Scientist                          Amicus   \n",
              "16                  Machine Learning Engineer                         Verneek   \n",
              "23                             Data Scientist                         Experfy   \n",
              "\n",
              "   Job_posted_date                                               Link  \\\n",
              "9       2022-12-01  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "20      2022-11-03  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "19      2022-11-09  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "2       2022-12-06  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "11      2022-12-01  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "14      2022-11-18  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "21      2022-11-01  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "13      2022-11-21  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "5       2022-12-03  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "6       2022-12-03  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "1       2022-12-06  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "24      2022-10-23  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "15      2022-11-18  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "8       2022-12-02  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "22      2022-10-31  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "17      2022-11-16  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "4       2022-12-06  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "12      2022-11-30  https://www.linkedin.com/jobs/view/machine-lea...   \n",
              "7       2022-12-02  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "0       2022-12-07  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "10      2022-12-01  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "18      2022-11-11  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "3       2022-12-06  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "16      2022-11-17  https://www.linkedin.com/jobs/view/machine-lea...   \n",
              "23      2022-10-27  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "\n",
              "    Matching_percentage  \n",
              "9             65.696219  \n",
              "20            63.033577  \n",
              "19            62.934231  \n",
              "2             62.874773  \n",
              "11            62.232565  \n",
              "14            61.385709  \n",
              "21            61.268327  \n",
              "13            60.544715  \n",
              "5             60.388366  \n",
              "6             59.261380  \n",
              "1             58.897015  \n",
              "24            58.681862  \n",
              "15            58.595426  \n",
              "8             58.214526  \n",
              "22            58.211078  \n",
              "17            58.176045  \n",
              "4             57.169240  \n",
              "12            56.472088  \n",
              "7             55.874025  \n",
              "0             55.166080  \n",
              "10            54.395568  \n",
              "18            51.273488  \n",
              "3             47.970391  \n",
              "16            47.075169  \n",
              "23            42.449092  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e117928-dec7-45de-9ba1-b48ad695c510\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Job_title</th>\n",
              "      <th>Company</th>\n",
              "      <th>Job_posted_date</th>\n",
              "      <th>Link</th>\n",
              "      <th>Matching_percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Data Scientist I</td>\n",
              "      <td>The Walt Disney Company</td>\n",
              "      <td>2022-12-01</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>65.696219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Afficiency</td>\n",
              "      <td>2022-11-03</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>63.033577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Afficiency</td>\n",
              "      <td>2022-11-09</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>62.934231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Data Scientist (Deep Learning), Peacock</td>\n",
              "      <td>Peacock</td>\n",
              "      <td>2022-12-06</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>62.874773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Data Scientist - Global Decision Science</td>\n",
              "      <td>American Express</td>\n",
              "      <td>2022-12-01</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>62.232565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Epsilon</td>\n",
              "      <td>2022-11-18</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>61.385709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>IntelliPro</td>\n",
              "      <td>2022-11-01</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>61.268327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>TikTok</td>\n",
              "      <td>2022-11-21</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>60.544715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>TikTok</td>\n",
              "      <td>2022-12-03</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>60.388366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>2022-12-03</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>59.261380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Data Scientist, Accounting</td>\n",
              "      <td>Spotify</td>\n",
              "      <td>2022-12-06</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>58.897015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Atlantic Partners Corporation</td>\n",
              "      <td>2022-10-23</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>58.681862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Carrie Rikon &amp; Associates, LLC</td>\n",
              "      <td>2022-11-18</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>58.595426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Data Scientist [NYC]</td>\n",
              "      <td>CarbonChain</td>\n",
              "      <td>2022-12-02</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>58.214526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Carrie Rikon &amp; Associates, LLC</td>\n",
              "      <td>2022-10-31</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>58.211078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Data Scientist, Product</td>\n",
              "      <td>Asana</td>\n",
              "      <td>2022-11-16</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>58.176045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Data Scientist Full Time</td>\n",
              "      <td>Bardess Group Ltd</td>\n",
              "      <td>2022-12-06</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>57.169240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Machine Learning Engineer - New Grad 2023</td>\n",
              "      <td>Nextdoor</td>\n",
              "      <td>2022-11-30</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
              "      <td>56.472088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Grammarly</td>\n",
              "      <td>2022-12-02</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>55.874025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Data Scientist (Remote)</td>\n",
              "      <td>Broadlume</td>\n",
              "      <td>2022-12-07</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>55.166080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Data Scientist I, Risk Analytics</td>\n",
              "      <td>Oscar Health</td>\n",
              "      <td>2022-12-01</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>54.395568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Revelio Labs</td>\n",
              "      <td>2022-11-11</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>51.273488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Amicus</td>\n",
              "      <td>2022-12-06</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>47.970391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Machine Learning Engineer</td>\n",
              "      <td>Verneek</td>\n",
              "      <td>2022-11-17</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
              "      <td>47.075169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Experfy</td>\n",
              "      <td>2022-10-27</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>42.449092</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e117928-dec7-45de-9ba1-b48ad695c510')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1e117928-dec7-45de-9ba1-b48ad695c510 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1e117928-dec7-45de-9ba1-b48ad695c510');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Here are the top 10 recommended jobs based on your resume:')\n",
        "final_info_table.nlargest(10,['Matching_percentage'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "z-zS2n0pgnF6",
        "outputId": "74d00653-4152-4c45-e91a-bcdc5d3dd97f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are the top 10 recommended jobs based on your resume:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   Job_title                  Company  \\\n",
              "9                           Data Scientist I  The Walt Disney Company   \n",
              "20                            Data Scientist               Afficiency   \n",
              "19                            Data Scientist               Afficiency   \n",
              "2    Data Scientist (Deep Learning), Peacock                  Peacock   \n",
              "11  Data Scientist - Global Decision Science         American Express   \n",
              "14                            Data Scientist                  Epsilon   \n",
              "21                            Data Scientist               IntelliPro   \n",
              "13                            Data Scientist                   TikTok   \n",
              "5                             Data Scientist                   TikTok   \n",
              "6                             Data Scientist       The New York Times   \n",
              "\n",
              "   Job_posted_date                                               Link  \\\n",
              "9       2022-12-01  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "20      2022-11-03  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "19      2022-11-09  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "2       2022-12-06  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "11      2022-12-01  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "14      2022-11-18  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "21      2022-11-01  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "13      2022-11-21  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "5       2022-12-03  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "6       2022-12-03  https://www.linkedin.com/jobs/view/data-scient...   \n",
              "\n",
              "    Matching_percentage  \n",
              "9             65.696219  \n",
              "20            63.033577  \n",
              "19            62.934231  \n",
              "2             62.874773  \n",
              "11            62.232565  \n",
              "14            61.385709  \n",
              "21            61.268327  \n",
              "13            60.544715  \n",
              "5             60.388366  \n",
              "6             59.261380  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d13e1efb-35ec-410f-8cf6-7232295b252c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Job_title</th>\n",
              "      <th>Company</th>\n",
              "      <th>Job_posted_date</th>\n",
              "      <th>Link</th>\n",
              "      <th>Matching_percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Data Scientist I</td>\n",
              "      <td>The Walt Disney Company</td>\n",
              "      <td>2022-12-01</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>65.696219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Afficiency</td>\n",
              "      <td>2022-11-03</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>63.033577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Afficiency</td>\n",
              "      <td>2022-11-09</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>62.934231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Data Scientist (Deep Learning), Peacock</td>\n",
              "      <td>Peacock</td>\n",
              "      <td>2022-12-06</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>62.874773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Data Scientist - Global Decision Science</td>\n",
              "      <td>American Express</td>\n",
              "      <td>2022-12-01</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>62.232565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>Epsilon</td>\n",
              "      <td>2022-11-18</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>61.385709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>IntelliPro</td>\n",
              "      <td>2022-11-01</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>61.268327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>TikTok</td>\n",
              "      <td>2022-11-21</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>60.544715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>TikTok</td>\n",
              "      <td>2022-12-03</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>60.388366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>The New York Times</td>\n",
              "      <td>2022-12-03</td>\n",
              "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
              "      <td>59.261380</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d13e1efb-35ec-410f-8cf6-7232295b252c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d13e1efb-35ec-410f-8cf6-7232295b252c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d13e1efb-35ec-410f-8cf6-7232295b252c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting skills from PDF ,First using our own defined Skills database and then using SkillsAPI \n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import requests\n",
        "from pdfminer.high_level import extract_text \n",
        "nltk.download('stopwords')\n",
        "#first we tried to extract skills that match skills in our list of SKILLS \n",
        "SKILLS_DB = [\n",
        "    'machine learning',\n",
        "    'data science',\n",
        "    'python',\n",
        "    'word',\n",
        "    'excel',\n",
        "    'English',\n",
        "    'Business development',\n",
        "    'Alteryx',\n",
        "    'Tensorflow',\n",
        "    'EDA',\n",
        "    'Modeling',\n",
        "    'Microsoft',\n",
        "    'Keras'\n",
        "] \n",
        "\n",
        "\n",
        "\n",
        " \n",
        " \n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    txt= extract_text(pdf_path)\n",
        "    if txt:\n",
        "       return txt.replace('\\t',' ')\n",
        "    return None\n",
        " \n",
        "def extract_skills(input_text):\n",
        "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "    word_tokens = nltk.tokenize.word_tokenize(input_text)\n",
        " \n",
        "    # remove the stop words\n",
        "    filtered_tokens = [w for w in word_tokens if w not in stop_words]\n",
        " \n",
        "    # remove the punctuation\n",
        "    filtered_tokens = [w for w in word_tokens if w.isalpha()]\n",
        " \n",
        "    # generate bigrams and trigrams\n",
        "    bigrams_trigrams = list(map(' '.join, nltk.everygrams(filtered_tokens, 2, 3)))\n",
        " \n",
        "    # we create a set to keep the results in.\n",
        "    found_skills = set()\n",
        " \n",
        "    # we search for each token in our skills database\n",
        "    for token in filtered_tokens:\n",
        "        if token.lower() in SKILLS_DB:\n",
        "            found_skills.add(token)\n",
        " \n",
        "    # we search for each bigram and trigram in our skills database\n",
        "    for ngram in bigrams_trigrams:\n",
        "        if ngram.lower() in SKILLS_DB:\n",
        "            found_skills.add(ngram)\n",
        " \n",
        "    return found_skills \n",
        " \n",
        " \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    text = extract_text_from_pdf('/content/ZeyaAhmadResume.pdf')\n",
        "    skills = extract_skills(text)\n",
        " \n",
        "    print(skills)  \n",
        "\n",
        "    #print(('/content/ZeyaAhmadResume.pdf'))\n",
        "\n",
        "\n",
        " \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhVwwSeVqdIv",
        "outputId": "d2340097-f783-4a42-c3ab-8d96b34b48da"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'word', 'Machine Learning', 'Excel', 'Data Science', 'Python'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Code for extracting skills from Resume using SkillsAPI which contains a predefined set of skills   \n",
        " \n",
        "def extract_text_from_pdf(pdf_path):\n",
        "  txt= extract_text(pdf_path)\n",
        "  if txt:\n",
        "     return txt.replace('\\t',' ')\n",
        "  return None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def skill_exists(skill):\n",
        "    url = f'https://api.apilayer.com/skills?q={skill}&amp;count=1'\n",
        "    headers = {'apikey': 'D9NceI0TAvzxRhROIUcgRpbzmEqZecSY'}\n",
        "    response = requests.request('GET', url, headers=headers)\n",
        "    result = response.json()\n",
        " \n",
        "    if response.status_code == 200:\n",
        "        return len(result) &gt; 0 and result[0].lower() == skill.lower()\n",
        "    raise Exception(result.get('message'))\n",
        " \n",
        " \n",
        "def extract_skills(input_text):\n",
        "    stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "    word_tokens = nltk.tokenize.word_tokenize(input_text)\n",
        " \n",
        "    # remove the stop words\n",
        "    filtered_tokens = [w for w in word_tokens if w not in stop_words]\n",
        " \n",
        "    # remove the punctuation\n",
        "    filtered_tokens = [w for w in word_tokens if w.isalpha()]\n",
        " \n",
        "    # generate bigrams and trigrams (such as artificial intelligence)\n",
        "    bigrams_trigrams = list(map(' '.join, nltk.everygrams(filtered_tokens, 2, 3)))\n",
        " \n",
        "    # we create a set to keep the results in.\n",
        "    found_skills = set()\n",
        " \n",
        "    # we search for each token in our skills database\n",
        "    for token in filtered_tokens:\n",
        "        if skill_exists(token.lower()):\n",
        "            found_skills.add(token)\n",
        " \n",
        "    # we search for each bigram and trigram in our skills database\n",
        "    for ngram in bigrams_trigrams:\n",
        "        if skill_exists(ngram.lower()):\n",
        "            found_skills.add(ngram)\n",
        " \n",
        "    return found_skills\n",
        " \n",
        " \n",
        "    \n"
      ],
      "metadata": {
        "id": "3IWZm4i2uQ7T"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rzq317lvuRCw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}