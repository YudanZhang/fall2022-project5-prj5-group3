{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80326149",
   "metadata": {},
   "source": [
    "## resume/CV Clean & Edit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9bb94c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2, pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c182794d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Weijia WangE-mail: ww2589@columbia.edu LinkedIn: https://www.linkedin.com/in/weijia-wwang Tel: (646)875-9590EDUCATIONColumbia University - NewYork, NY Sep 2021 - Dec 2022\\uf077 M.A.inStatistics(Coursework:StatisticalInference,Probability,LinearRegression,BayesStatistics,DataScience)Capital University ofEconomics andBusiness -Beijing, CN Sep 2016 - Jun2020\\uf077 B.S.inEconomicStatistics(Coursework:AdvancedDataanalysis,StatisticalMachineLearning,IntrotoDataBase)SKILLS\\uf077 Programming Languages andDatabases: Python, R, SQL Server, MySQL, Hive, Spark, MangoDB, ETL\\uf077 Data Visualization tools:Tableau, PowerBI, QlikSense, Matplotlib, Seaborn, Pycharts, ggplot2\\uf077 Data Sciencetools andpackages: NLP, A/B test, Excel, Pandas, Numpy, Sklearn, TensorflowWORK EXPERIENCEBankofChina, NewYork Branch NewYork, NY Jun 2022-Aug 2022DataAnalyst Intern\\uf077 Built datadashboards using QlikSensetoshowwork stream data of81audits and kept track of ongoingprojects, supporting leadership to make datadriven decisions, optimized resource distribution by10%\\uf077 Monitored suspicious transactionsbyexecuting analysis using SQL server. Withdaily data exposureof100Ktransactions, formed operation report of300+ risky records regarding account activities, risk levels\\uf077 Participated instakeholder meetings with cross-functional team, explained data analysis results72Dragons FilmProductions,LLC NewYork, NY May2022- Sep 2022Data Scientist Intern\\uf077 Led ateam of3to make interactive datadashboards usinglarge-scale datavisualization methods such asShiny inR to demonstratetheimpact offilm festivals ontherevenue offilmsand delivered suggestions\\uf077 Designed web scrappers to collect 70K filmfestival and boxoffice data from 10+websites,200+countries\\uf077 Developed data pre-processing workflowwith Pandas package in Python to convert rawdata intocleaneddata,automated data pipelinebywriting ETL process and saved 70%data processing timefor DS teamSo-Young International Inc. Beijing, CN Sep 2020-Apr 2021DataAnalyst Intern\\uf077 Collaborated with product managers to set upcompany-wide data dashboardsand keep track of300+advertisement resources, improved efficiency for theBusiness Development team by50%.\\uf077 Conducted A/B testinganalysis incorporation with product management team, tested theperformance ofcertain banner and improved userretention rate by14%.Used SQL and Excel toprovideStatistical report\\uf077 Examined 188existing SQL queries, suggested new queries to optimizeperformance onaCloud serverLenovoGroupLimited Beijing, CN Nov 2019 -Jan 2020Data Scientist Intern\\uf077 Adapted Word2vecand TF-IDF with Python to convert descriptive sentences into vectors in App Store\\uf077 Calculated similarity ofapplication description foruser recommendationsystem usingClustering Methods,Gradient Boosting Decision Tree combiningLogisticRegression Analysis and Deep Learning method(Neural Network).Increased Click-Through-Rate upto73% fortherecommendation algorithm\\uf077 Tested the performance ofdifferent Machine Learning models on300,000+users,presented to groupleaderPROJECT EXPERIENCEFactorAnalysis ofInfluencers onTraditional Products Selling Feb2019- Jul2020\\uf077 Led a team of 6 and awarded National 3rd Prize for analysis project on collaboration effects of traditionalbusiness andsocial influencer,delivered market research report and presentation oncurrent market\\uf077 Applied PCA to select features, analyzed the reasons for virtual influencers to be more profitable andpopular inpublicbyclustering themusing Decision Tree, Regression,XGBoost, SVM and Neural Network.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Target File\n",
    "CV = \"resume.pdf\"\n",    #
    "CV_File=open(CV,'rb')\n",
    "Script=PyPDF2.PdfFileReader(CV_File)\n",
    "pages=Script.numPages\n",
    "\n",
    "Script = []\n",
    "with pdfplumber.open(CV_File) as pdf:\n",
    "    for i in range (0,pages):\n",
    "        page=pdf.pages[i]\n",
    "        text=page.extract_text()\n",
    "        # print (text)\n",
    "        Script.append(text)\n",
    "        \n",
    "Script=''.join(Script)\n",
    "CV_Clear = Script.replace(\"\\n\",\"\").replace('‚óè', \"\")\n",
    "CV_Clear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc33586",
   "metadata": {},
   "source": [
    "## job searching based on input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1b495c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# test if successfully script info from website\n",
    "import requests\n",
    "agent = {'User-agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36'}\n",
    "r = requests.get(\"https://www.linkedin.com/jobs/view/data-analyst-at-parsley-health-3385039452?refId=M8kI1Wa%2B8le267Tw1HteqA%3D%3D&trackingId=0cr1swLF7wVNfz1KztO9AA%3D%3D&position=3&pageNum=0&trk=public_jobs_jserp-result_search-card\", headers = agent)\n",
    "print(r.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fbb5081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d74dbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your desired position: Data Scientist\n",
      "Enter your desired location: New York\n",
      "Enter the # of pages to scrape: 5\n",
      "https://www.linkedin.com/jobs/search?keywords=Data+Scientist&location=New+York&sort=date&start=50\n",
      "https://www.linkedin.com/jobs/search?keywords=Machine+Learning+Engineer+%28NLP%29&location=New+York&sort=date&start=50\n",
      "https://www.linkedin.com/jobs/search?keywords=Machine+Learning+Engineer&location=New+York&sort=date&start=50\n",
      "https://www.linkedin.com/jobs/search?keywords=Data+Scientist+%28Remote%29&location=New+York&sort=date&start=50\n",
      "https://www.linkedin.com/jobs/search?keywords=Lead%2C+Data+Scientist+%28Deep+Learning%29%2C+Peacock+Video+Streaming&location=New+York&sort=date&start=50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Job_posted_date</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist Full Time</td>\n",
       "      <td>Bardess Group Ltd</td>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist Full Time</td>\n",
       "      <td>Bardess Group Ltd</td>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>CareerWellness</td>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist Full Time</td>\n",
       "      <td>Bardess Group Ltd</td>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ML Engineer Internship - Accelerate</td>\n",
       "      <td>Hugging Face</td>\n",
       "      <td>2022-12-05</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/ml-engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Data Scientist/AI Engineer - US - Remote</td>\n",
       "      <td>Within3</td>\n",
       "      <td>2022-10-03</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Machine Learning Engineer (NLP)</td>\n",
       "      <td>BLACKBIRD.AI</td>\n",
       "      <td>2022-09-11</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Machine Learning Engineer (NLP)</td>\n",
       "      <td>BLACKBIRD.AI</td>\n",
       "      <td>2022-09-11</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Machine Learning Engineer (NLP)</td>\n",
       "      <td>BLACKBIRD.AI</td>\n",
       "      <td>2022-09-11</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Machine Learning Engineer (NLP)</td>\n",
       "      <td>BLACKBIRD.AI</td>\n",
       "      <td>2022-09-11</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Job_title            Company  \\\n",
       "0                    Data Scientist Full Time  Bardess Group Ltd   \n",
       "1                    Data Scientist Full Time  Bardess Group Ltd   \n",
       "2                   Machine Learning Engineer     CareerWellness   \n",
       "3                    Data Scientist Full Time  Bardess Group Ltd   \n",
       "4         ML Engineer Internship - Accelerate       Hugging Face   \n",
       "..                                        ...                ...   \n",
       "96   Data Scientist/AI Engineer - US - Remote            Within3   \n",
       "97            Machine Learning Engineer (NLP)       BLACKBIRD.AI   \n",
       "98            Machine Learning Engineer (NLP)       BLACKBIRD.AI   \n",
       "99            Machine Learning Engineer (NLP)       BLACKBIRD.AI   \n",
       "100           Machine Learning Engineer (NLP)       BLACKBIRD.AI   \n",
       "\n",
       "    Job_posted_date                                               Link  \n",
       "0        2022-12-06  https://www.linkedin.com/jobs/view/data-scient...  \n",
       "1        2022-12-06  https://www.linkedin.com/jobs/view/data-scient...  \n",
       "2        2022-12-06  https://www.linkedin.com/jobs/view/machine-lea...  \n",
       "3        2022-12-06  https://www.linkedin.com/jobs/view/data-scient...  \n",
       "4        2022-12-05  https://www.linkedin.com/jobs/view/ml-engineer...  \n",
       "..              ...                                                ...  \n",
       "96       2022-10-03  https://www.linkedin.com/jobs/view/data-scient...  \n",
       "97       2022-09-11  https://www.linkedin.com/jobs/view/machine-lea...  \n",
       "98       2022-09-11  https://www.linkedin.com/jobs/view/machine-lea...  \n",
       "99       2022-09-11  https://www.linkedin.com/jobs/view/machine-lea...  \n",
       "100      2022-09-11  https://www.linkedin.com/jobs/view/machine-lea...  \n",
       "\n",
       "[101 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search inputs: \n",
    "title = input('Enter your desired position: ').strip()\n",
    "location = input('Enter your desired location: ').strip()\n",
    "no_pages = int(input('Enter the # of pages to scrape: '))\n",
    "\n",
    "\n",
    "info = []\n",
    "headers = {'User-agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36'}\n",
    "\n",
    "for page in range(no_pages):\n",
    "    getVars = {'keywords' : title, 'location' : location ,'sort' : 'date', 'start': str(no_pages*10)}\n",
    "    url = ('https://www.linkedin.com/jobs/search?' + urllib.parse.urlencode(getVars))\n",
    "    print(url)\n",
    "    r = requests.get(url, headers=headers)\n",
    "    html = r.content\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    jobs = soup.find_all('div', class_ = 'base-card relative w-full hover:no-underline focus:no-underline base-card--link base-search-card base-search-card--link job-search-card')\n",
    "    \n",
    "    for job in jobs:\n",
    "        title = str(job.find('h3', class_='base-search-card__title').text.strip())\n",
    "        company = str(job.find('h4', class_='base-search-card__subtitle').text.strip())\n",
    "        post_date = datetime.strptime(job.find('time')['datetime'], '%Y-%m-%d').date()\n",
    "        link = job.find('a', class_='base-card__full-link')['href']\n",
    "        \n",
    "        info.append([title,company,post_date,link])\n",
    "    \n",
    "\n",
    "info_dict_list = defaultdict(list)\n",
    "\n",
    "cols = ['Job_title','Company','Job_posted_date','Link']\n",
    "info_table = pd.DataFrame(info, columns = cols)\n",
    "# sort by post date\n",
    "info_table = info_table.sort_values(by = 'Job_posted_date', ascending = False).reset_index(drop=True)\n",
    "info_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6a84de",
   "metadata": {},
   "source": [
    "## match based on search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "beee6cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20b0581e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50.41776927921554,\n",
       " 50.41776927921554,\n",
       " 48.96038993648835,\n",
       " 50.41776927921554,\n",
       " 32.6373072235272,\n",
       " 40.985088466063004,\n",
       " 49.42106202759021,\n",
       " 40.985088466063004,\n",
       " 49.07820003815833,\n",
       " 46.190089108447005,\n",
       " 45.45380682201572,\n",
       " 45.45380682201572,\n",
       " 45.45380682201572,\n",
       " 45.98551186089511,\n",
       " 47.024907887765806,\n",
       " 47.024907887765806,\n",
       " 36.62388060745903,\n",
       " 49.48728176488349,\n",
       " 44.98091772287607,\n",
       " 52.96921014456625,\n",
       " 49.48728176488349,\n",
       " 46.46094776094405,\n",
       " 43.41052756714046,\n",
       " 41.86844683522939,\n",
       " 55.23778736493568,\n",
       " 43.41052756714046,\n",
       " 49.72739662434324,\n",
       " 42.57062780106055,\n",
       " 55.23778736493568,\n",
       " 41.86844683522939,\n",
       " 41.10386560148183,\n",
       " 43.41052756714046,\n",
       " 49.46571388422114,\n",
       " 40.89162668177946,\n",
       " 51.844782296291456,\n",
       " 45.14499755371209,\n",
       " 51.844782296291456,\n",
       " 45.14499755371209,\n",
       " 29.02376525816919,\n",
       " 38.4212087448207,\n",
       " 41.14413991346742,\n",
       " 38.64665244715494,\n",
       " 34.302230799778265,\n",
       " 38.299579941019516,\n",
       " 46.23638431475096,\n",
       " 52.07557536978062,\n",
       " 46.8546294120053,\n",
       " 46.8546294120053,\n",
       " 38.38661262041431,\n",
       " 49.012719759530206,\n",
       " 47.78249382304507,\n",
       " 47.78249382304507,\n",
       " 54.462897727730166,\n",
       " 48.994190276868274,\n",
       " 50.83758622895657,\n",
       " 35.731300781543695,\n",
       " 35.731300781543695,\n",
       " 35.731300781543695,\n",
       " 51.49680296821614,\n",
       " 46.06562823670727,\n",
       " 51.49680296821614,\n",
       " 24.939838680694397,\n",
       " 26.710361214824772,\n",
       " 45.67228020190485,\n",
       " 26.108325726963834,\n",
       " 27.78956772855506,\n",
       " 45.682598190130236,\n",
       " 27.78956772855506,\n",
       " 17.197384204220352,\n",
       " 45.485175202156334,\n",
       " 35.765002370360946,\n",
       " 35.765002370360946,\n",
       " 35.872711287193496,\n",
       " 35.872711287193496,\n",
       " 35.455538785471155,\n",
       " 49.164019982264676,\n",
       " 54.18581271542715,\n",
       " 50.41776927921554,\n",
       " 50.41776927921554,\n",
       " 54.45213462330902,\n",
       " 45.94556390362109,\n",
       " 54.45213462330902,\n",
       " 50.59724012352505,\n",
       " 50.59724012352505,\n",
       " 49.03055741563974,\n",
       " 34.302230799778265,\n",
       " 34.302230799778265,\n",
       " 34.302230799778265,\n",
       " 35.780211415666564,\n",
       " 55.47884935482459,\n",
       " 45.64817885088016,\n",
       " 47.42333488364778,\n",
       " 39.18097648483063,\n",
       " 41.27964915018374,\n",
       " 41.27964915018374,\n",
       " 41.27964915018374,\n",
       " 43.014170705693914,\n",
       " 47.15281392409915,\n",
       " 47.15281392409915,\n",
       " 47.15281392409915,\n",
       " 47.15281392409915]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_percent = []\n",
    "for l in info_table['Link']: \n",
    "    \n",
    "    # extract job description from 2nd webpage (ie, main page for each job post)\n",
    "    r = requests.get(l, headers=headers)\n",
    "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "    job_description = soup.find('div', class_='show-more-less-html__markup show-more-less-html__markup--clamp-after-5').text.replace(\"\\n\",\"\")\n",
    "    \n",
    "    # calculate match percentage \n",
    "    Match_Test = [CV_Clear,job_description]\n",
    "    cv = CountVectorizer()\n",
    "    count_matrix = cv.fit_transform(Match_Test)\n",
    "    MatchPercentage = cosine_similarity(count_matrix)[0][1]*100\n",
    "    match_percent.append(MatchPercentage)\n",
    "    \n",
    "match_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4c3c6436",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_percent = pd.DataFrame(match_percent, columns = ['Matching_percentage'])\n",
    "final_info_table = pd.concat([info_table, match_percent], axis=1)\n",
    "final_info_table = final_info_table.sort_values(by = 'Matching_percentage', axis = 0, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc12aa5b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Job_posted_date</th>\n",
       "      <th>Link</th>\n",
       "      <th>Matching_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Atlantic Partners Corporation</td>\n",
       "      <td>2022-10-23</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "      <td>55.478849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>The Walt Disney Company</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "      <td>55.237787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>The Walt Disney Company</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "      <td>55.237787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Data Scientist (REMOTE)</td>\n",
       "      <td>Foot Locker</td>\n",
       "      <td>2022-11-20</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "      <td>54.462898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Afficiency</td>\n",
       "      <td>2022-11-03</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "      <td>54.452135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Junior Machine Learning</td>\n",
       "      <td>Diverse Lynx</td>\n",
       "      <td>2022-11-16</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/junior-mach...</td>\n",
       "      <td>27.789568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Diverse Lynx</td>\n",
       "      <td>2022-11-16</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
       "      <td>26.710361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Junior Machine Learning Developer</td>\n",
       "      <td>Diverse Lynx</td>\n",
       "      <td>2022-11-16</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/junior-mach...</td>\n",
       "      <td>26.108326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Junior Machine Learning</td>\n",
       "      <td>Diverse Lynx</td>\n",
       "      <td>2022-11-16</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/junior-mach...</td>\n",
       "      <td>24.939839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>ACHIEVA Group Limited</td>\n",
       "      <td>2022-11-15</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
       "      <td>17.197384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Job_title                        Company  \\\n",
       "89                     Data Scientist  Atlantic Partners Corporation   \n",
       "24                   Data Scientist I        The Walt Disney Company   \n",
       "28                   Data Scientist I        The Walt Disney Company   \n",
       "52            Data Scientist (REMOTE)                    Foot Locker   \n",
       "81                     Data Scientist                     Afficiency   \n",
       "..                                ...                            ...   \n",
       "67            Junior Machine Learning                   Diverse Lynx   \n",
       "62          Machine Learning Engineer                   Diverse Lynx   \n",
       "64  Junior Machine Learning Developer                   Diverse Lynx   \n",
       "61            Junior Machine Learning                   Diverse Lynx   \n",
       "68          Machine Learning Engineer          ACHIEVA Group Limited   \n",
       "\n",
       "   Job_posted_date                                               Link  \\\n",
       "89      2022-10-23  https://www.linkedin.com/jobs/view/data-scient...   \n",
       "24      2022-12-01  https://www.linkedin.com/jobs/view/data-scient...   \n",
       "28      2022-12-01  https://www.linkedin.com/jobs/view/data-scient...   \n",
       "52      2022-11-20  https://www.linkedin.com/jobs/view/data-scient...   \n",
       "81      2022-11-03  https://www.linkedin.com/jobs/view/data-scient...   \n",
       "..             ...                                                ...   \n",
       "67      2022-11-16  https://www.linkedin.com/jobs/view/junior-mach...   \n",
       "62      2022-11-16  https://www.linkedin.com/jobs/view/machine-lea...   \n",
       "64      2022-11-16  https://www.linkedin.com/jobs/view/junior-mach...   \n",
       "61      2022-11-16  https://www.linkedin.com/jobs/view/junior-mach...   \n",
       "68      2022-11-15  https://www.linkedin.com/jobs/view/machine-lea...   \n",
       "\n",
       "    Matching_percentage  \n",
       "89            55.478849  \n",
       "24            55.237787  \n",
       "28            55.237787  \n",
       "52            54.462898  \n",
       "81            54.452135  \n",
       "..                  ...  \n",
       "67            27.789568  \n",
       "62            26.710361  \n",
       "64            26.108326  \n",
       "61            24.939839  \n",
       "68            17.197384  \n",
       "\n",
       "[101 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export tp csv file: \n",
    "final_info_table.to_csv('final_info_table1.csv', index=False)\n",
    "final_info_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d865a608",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Here are the top 10 recommended jobs based on your resume:')\n",
    "final_info_table.nlargest(10,['Matching_percentage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb6fc42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
